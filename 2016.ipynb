{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c6eba0-b412-419a-adbe-ad52f4a10ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique delivery charges:\n",
      "[ 0. nan 40.]\n",
      "delivery_charges\n",
      "0.0     1127601\n",
      "40.0          8\n",
      "Name: count, dtype: int64\n",
      "customer_age_group:\n",
      "['36-45' nan '46-55' '18-25' '26-35' '55+']\n",
      "festival_name:\n",
      "[nan 'Summer Sale' 'Back to School' 'Diwali Sale' 'Holi Festival'\n",
      " 'Amazon Great Indian Festival' 'Republic Day Sale' 'Valentine Sale'\n",
      " 'Prime Day']\n",
      "Mean customer_rating: 4.316058126956314\n",
      "0     27340.84\n",
      "1     32907.49\n",
      "2     47052.18\n",
      "3    238725.44\n",
      "4     25970.76\n",
      "Name: original_price_inr, dtype: float64\n",
      "float64\n",
      "      transaction_id  order_date         customer_id   product_id  \\\n",
      "0  TXN_2023_00063013  2023-07-23  CUST_2023_00018393  PROD_000454   \n",
      "1  TXN_2021_00064486  20-07-2021  CUST_2015_00002865  PROD_000579   \n",
      "2  TXN_2017_00065617  2017-11-16  CUST_2016_00004057  PROD_000295   \n",
      "3  TXN_2020_00054393  2020-05-04  CUST_2020_00014574  PROD_001654   \n",
      "4  TXN_2018_00071646  2018-10-09  CUST_2018_00006275  PROD_000095   \n",
      "\n",
      "                        product_name     category  subcategory      brand  \\\n",
      "0                Vivo Y95 64GB Black  Electronics  Smartphones       Vivo   \n",
      "1        Realme Realme 3 128GB Black  Electronics  Smartphones     Realme   \n",
      "2                  Vivo V7 32GB Blue  Electronics  Smartphones       Vivo   \n",
      "3  Alienware Pavilion 4GB RAM Silver  Electronics      Laptops  Alienware   \n",
      "4    Motorola Moto X Play 16GB White  Electronics  Smartphones   Motorola   \n",
      "\n",
      "   original_price_inr  discount_percent  ...  is_festival_sale  festival_name  \\\n",
      "0            27340.84             21.57  ...             False     Normal_day   \n",
      "1            32907.49              0.00  ...             False     Normal_day   \n",
      "2            47052.18             21.91  ...             False     Normal_day   \n",
      "3           238725.44             59.60  ...              True    Summer Sale   \n",
      "4            25970.76              0.00  ...             False     Normal_day   \n",
      "\n",
      "   customer_rating return_status order_month order_year order_quarter  \\\n",
      "0         4.000000     Delivered           7       2023             3   \n",
      "1         4.316058     Delivered           7       2021             3   \n",
      "2         5.000000     Delivered          11       2017             4   \n",
      "3         4.316058     Delivered           5       2020             2   \n",
      "4         4.000000     Delivered          10       2018             4   \n",
      "\n",
      "  product_weight_kg is_prime_eligible product_rating  \n",
      "0              0.20              True            3.5  \n",
      "1              0.21             False            4.5  \n",
      "2              0.24              True            4.3  \n",
      "3              1.85               Yes            3.6  \n",
      "4              0.16             False            3.7  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "curtomer_city:\n",
      "['Kolkata' 'Ludhiana' 'Bangalore' 'Kochi' 'Mumbai' 'Delhi' 'Aligarh'\n",
      " 'Surat' 'Kanpur' 'Chennai' 'Hyderabad' 'Bareilly' 'Vadodara' 'Indore'\n",
      " 'Visakhapatnam' 'Lucknow' 'Pune' 'Bhubaneswar' 'Nagpur' 'Patna'\n",
      " 'Ahmedabad' 'Jaipur' 'Meerut' 'Allahabad' 'Varanasi' 'Coimbatore'\n",
      " 'Moradabad' 'Saharanpur' 'Chandigarh' 'Gorakhpur']\n",
      "customer_city\n",
      "Mumbai           141644\n",
      "Delhi            123469\n",
      "Bangalore        102523\n",
      "Chennai           84753\n",
      "Pune              67703\n",
      "Kolkata           66867\n",
      "Ahmedabad         50861\n",
      "Hyderabad         44573\n",
      "Jaipur            40453\n",
      "Surat             40400\n",
      "Nagpur            37211\n",
      "Kanpur            34334\n",
      "Lucknow           34077\n",
      "Indore            33592\n",
      "Coimbatore        26695\n",
      "Kochi             24940\n",
      "Visakhapatnam     22167\n",
      "Patna             21339\n",
      "Vadodara          21078\n",
      "Bhubaneswar       20472\n",
      "Chandigarh        19575\n",
      "Ludhiana          18891\n",
      "Saharanpur         6705\n",
      "Meerut             6641\n",
      "Bareilly           6590\n",
      "Aligarh            6407\n",
      "Allahabad          6030\n",
      "Varanasi           5897\n",
      "Gorakhpur          5867\n",
      "Moradabad          5855\n",
      "Name: count, dtype: int64\n",
      "Unique customer_state: ['West Bengal' 'Punjab' 'Karnataka' 'Kerala' 'Maharashtra' 'Delhi'\n",
      " 'Uttar Pradesh' 'Gujarat' 'Tamil Nadu' 'Telangana' 'Madhya Pradesh'\n",
      " 'Andhra Pradesh' 'Odisha' 'Bihar' 'Rajasthan']\n",
      "Unique customer_tier: ['Metro' 'Tier2' 'Rural' 'Tier1']\n",
      "Unique customer_spending_tier: ['Standard' 'Premium' 'Budget']\n",
      "unique payment_method: ['COD' 'UPI' 'Debit Card' 'Credit Card' 'Net Banking' 'Wallet' 'BNPL']\n",
      "unique delivery_type: ['Standard' 'Express' 'Same Day']\n",
      "payment_method\n",
      "UPI            384228\n",
      "COD            322831\n",
      "Credit Card    172261\n",
      "Debit Card     140202\n",
      "Net Banking     64971\n",
      "Wallet          22821\n",
      "BNPL            20295\n",
      "Name: count, dtype: int64\n",
      "âœ… Updated payment method counts:\n",
      "payment_method\n",
      "UPI            384228\n",
      "COD            322831\n",
      "Credit Card    172261\n",
      "Debit Card     140202\n",
      "Net Banking     64971\n",
      "Name: count, dtype: int64\n",
      "Delivery type counts:\n",
      " delivery_type\n",
      "Standard    759618\n",
      "Same Day    203084\n",
      "Express     121791\n",
      "Name: count, dtype: int64\n",
      "Number of High variation rows: 5163\n",
      "         original_price_inr  discount_percent  discounted_price_inr  \\\n",
      "0                     27341                22                 21443   \n",
      "1                     32907                 0                 32907   \n",
      "2                     47052                22                 36741   \n",
      "3                    238725                60                 96456   \n",
      "4                     25971                 0                 25971   \n",
      "...                     ...               ...                   ...   \n",
      "1127604              134278                31                 92886   \n",
      "1127605               97579                 0                 97579   \n",
      "1127606              105284                43                 59684   \n",
      "1127607               72687                 0                 72687   \n",
      "1127608                7093                 0                  7093   \n",
      "\n",
      "         calculated_discounted_price  variation_percent variation_flag  \n",
      "0                            21326.0               0.55             OK  \n",
      "1                            32907.0               0.00             OK  \n",
      "2                            36701.0               0.11             OK  \n",
      "3                            95490.0               1.01             OK  \n",
      "4                            25971.0               0.00             OK  \n",
      "...                              ...                ...            ...  \n",
      "1127604                      92652.0               0.25             OK  \n",
      "1127605                      97579.0               0.00             OK  \n",
      "1127606                      60012.0               0.55             OK  \n",
      "1127607                      72687.0               0.00             OK  \n",
      "1127608                       7093.0               0.00             OK  \n",
      "\n",
      "[1084493 rows x 6 columns]\n",
      "Rows after removing High variation: 1079330\n",
      "Number of rows present: 1079330\n",
      "Number of wrong rows: 116095\n",
      "         discounted_price_inr  quantity  final_amount_inr amount_check\n",
      "0                       21443         1             21443      correct\n",
      "1                       32907         3             98722        wrong\n",
      "2                       36741         1             36741      correct\n",
      "3                       96456         1             96456      correct\n",
      "4                       25971         1             25971      correct\n",
      "...                       ...       ...               ...          ...\n",
      "1079325                 92886         1             92886      correct\n",
      "1079326                 97579         1             97579      correct\n",
      "1079327                 59684         1             59684      correct\n",
      "1079328                 72687         1             72687      correct\n",
      "1079329                  7093         3             21278        wrong\n",
      "\n",
      "[1079330 rows x 4 columns]\n",
      "Rows after removing wrong amounts: 963235\n",
      "  customer_age_group  age_group_label\n",
      "0              36-45                3\n",
      "1              36-45                3\n",
      "2              46-55                4\n",
      "3              18-25                1\n",
      "4              26-35                2\n",
      "Number of rows with 17 in age_group_label: 115601\n",
      "Rows after removing age_group_label 0: 847634\n",
      "Number of rows present: 847634\n",
      "Unique prime_member: ['False' '0' '1' 'True' 'Yes' 'No' 'FALSE' 'TRUE']\n",
      "is_prime_member\n",
      "False    482889\n",
      "True     288667\n",
      "0         16000\n",
      "FALSE     15983\n",
      "No        15739\n",
      "Yes        9532\n",
      "1          9485\n",
      "TRUE       9339\n",
      "Name: count, dtype: int64\n",
      "Rows after removing age_group_label 0: 822149\n",
      "customer_rating: [4.         5.         4.31605813 4.5        3.         3.5       ]\n",
      "customer_rating\n",
      "4.316058    290436\n",
      "4.500000    179166\n",
      "5.000000    136785\n",
      "4.000000    129896\n",
      "3.500000     55491\n",
      "3.000000     30375\n",
      "Name: count, dtype: int64\n",
      "is_prime_eligible: ['True' 'Yes' 'False' 'TRUE' '1' 'FALSE' '0' 'No']\n",
      "is_prime_eligible\n",
      "True     612791\n",
      "False    135556\n",
      "1         20171\n",
      "TRUE      20118\n",
      "Yes       20069\n",
      "FALSE      4499\n",
      "No         4488\n",
      "0          4457\n",
      "Name: count, dtype: int64\n",
      "Rows after removing age_group_label 0: 797521\n",
      "delivery_days: ['3' '6' '4' '5' '1' 'Same Day' '1-2 days' '2' '7' '-1' '15' 'Express' '0']\n",
      "delivery_days\n",
      "3           204932\n",
      "4           147300\n",
      "1           146218\n",
      "5            97556\n",
      "2            87929\n",
      "6            73254\n",
      "7            24298\n",
      "-1            4817\n",
      "1-2 days      3267\n",
      "Same Day      3207\n",
      "Express       1646\n",
      "15            1557\n",
      "0             1540\n",
      "Name: count, dtype: int64\n",
      "Rows after removing age_group_label 0: 783044\n",
      "Rows after removing order_date_clean: 736043\n",
      "               customer_id  order_date   product_id  original_price_inr  \\\n",
      "0       CUST_2023_00018393  2023-07-23  PROD_000454               27341   \n",
      "1       CUST_2016_00004057  2017-11-16  PROD_000295               47052   \n",
      "2       CUST_2020_00014574  2020-05-04  PROD_001654              238725   \n",
      "3       CUST_2018_00006275  2018-10-09  PROD_000095               25971   \n",
      "5       CUST_2019_00028838  2019-10-22  PROD_000178               39859   \n",
      "...                    ...         ...          ...                 ...   \n",
      "847627  CUST_2017_00026004  2020-11-08  PROD_000478               36950   \n",
      "847628  CUST_2020_00042010  2020-08-14  PROD_000131              175679   \n",
      "847629  CUST_2016_00009514  2018-10-16  PROD_000479               30149   \n",
      "847630  CUST_2017_00025689  2018-07-06  PROD_000009              134278   \n",
      "847631  CUST_2021_00026763  2022-07-23  PROD_001732               97579   \n",
      "\n",
      "       duplicate_flag  \n",
      "0              unique  \n",
      "1              unique  \n",
      "2              unique  \n",
      "3              unique  \n",
      "5              unique  \n",
      "...               ...  \n",
      "847627         unique  \n",
      "847628         unique  \n",
      "847629         unique  \n",
      "847630         unique  \n",
      "847631         unique  \n",
      "\n",
      "[736043 rows x 5 columns]\n",
      "Rows after duplicate_clean: 732428\n",
      "Null count per column:\n",
      "transaction_id            0\n",
      "order_date                0\n",
      "customer_id               0\n",
      "product_id                0\n",
      "product_name              0\n",
      "category                  0\n",
      "subcategory               0\n",
      "brand                     0\n",
      "original_price_inr        0\n",
      "discount_percent          0\n",
      "discounted_price_inr      0\n",
      "quantity                  0\n",
      "final_amount_inr          0\n",
      "customer_city             0\n",
      "customer_state            0\n",
      "customer_tier             0\n",
      "customer_spending_tier    0\n",
      "payment_method            0\n",
      "delivery_days             0\n",
      "delivery_type             0\n",
      "is_prime_member           0\n",
      "festival_name             0\n",
      "customer_rating           0\n",
      "return_status             0\n",
      "order_month               0\n",
      "order_year                0\n",
      "order_quarter             0\n",
      "product_weight_kg         0\n",
      "is_prime_eligible         0\n",
      "product_rating            0\n",
      "age_group_label           0\n",
      "dtype: int64\n",
      "\n",
      "Total null values: 0\n",
      "\n",
      "Rows with null values:\n",
      "Empty DataFrame\n",
      "Columns: [transaction_id, order_date, customer_id, product_id, product_name, category, subcategory, brand, original_price_inr, discount_percent, discounted_price_inr, quantity, final_amount_inr, customer_city, customer_state, customer_tier, customer_spending_tier, payment_method, delivery_days, delivery_type, is_prime_member, festival_name, customer_rating, return_status, order_month, order_year, order_quarter, product_weight_kg, is_prime_eligible, product_rating, age_group_label]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 31 columns]\n",
      "Number of outliers to delete: 23541\n",
      "Rows before deletion: 732428\n",
      "Rows after deletion: 708887\n",
      "Deleted rows: 23541\n",
      "['Electronics' 'Electronicss' 'Electronic' 'ELECTRONICS'\n",
      " 'Electronics & Accessories']\n",
      "category\n",
      "Electronics                  731866\n",
      "Electronic                      149\n",
      "ELECTRONICS                     141\n",
      "Electronics & Accessories       141\n",
      "Electronicss                    131\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "Electronics    732428\n",
      "Name: count, dtype: int64\n",
      "âœ… Cleaned file saved at: C:\\Users\\Alagu\\DATASCIENCE\\Cleaned_data\\amazon_india_complete_2015_2025_cleaned_03.csv\n",
      "âœ… Cleaned file saved as 'cleaned_file.csv'\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = r\"C:\\Users\\Alagu\\DATASCIENCE\\amazon_india_complete_2015_2025.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "#print(df.dtypes)\n",
    "\n",
    "#Delivery_charges_Cleaning\n",
    "# Find unique values in delivery_charges\n",
    "unique_delivery_charges = df['delivery_charges'].unique()\n",
    "\n",
    "print(\"Unique delivery charges:\")\n",
    "print(unique_delivery_charges)\n",
    "\n",
    "# Replace null/NaN in delivery_charges with 0.0\n",
    "df['delivery_charges'] = df['delivery_charges'].fillna(0.0)\n",
    "\n",
    "value_counts = df['delivery_charges'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "#Customer-age-group-cleaning\n",
    "# Find unique values in customer_age_group\n",
    "unique_customer_age_group = df['customer_age_group'].unique()\n",
    "\n",
    "# Replace null in customer_age_group\n",
    "df['customer_age_group'] = df['customer_age_group'].fillna(17)\n",
    "\n",
    "print(\"customer_age_group:\")\n",
    "print(unique_customer_age_group)\n",
    "\n",
    "#Festival_name_sale\n",
    "# Find unique values in festival_name\n",
    "unique_festival_name = df['festival_name'].unique()\n",
    "\n",
    "# Replace null in festival_name\n",
    "df['festival_name'] = df['festival_name'].fillna(\"Normal_day\")\n",
    "\n",
    "print(\"festival_name:\")\n",
    "print(unique_festival_name)\n",
    "\n",
    "#Customer-rating\n",
    "# Find unique values in customer_rating\n",
    "unique_customer_rating = df['customer_rating'].unique()\n",
    "\n",
    "# Convert customer_rating to numeric (coerce errors to NaN)\n",
    "df['customer_rating'] = pd.to_numeric(df['customer_rating'], errors='coerce')\n",
    "\n",
    "# Calculate mean (ignores NaN)\n",
    "mean_rating = df['customer_rating'].mean()\n",
    "print(f\"Mean customer_rating: {mean_rating}\")\n",
    "\n",
    "# Fill NaN values with mean\n",
    "df['customer_rating'] = df['customer_rating'].fillna(mean_rating)\n",
    "\n",
    "# ðŸ”¹ Show total null values in each column\n",
    "#print(df.isnull().sum())\n",
    "\n",
    "#delivery_charges_delete\n",
    "# Delete the delivery_charges column\n",
    "df = df.drop(columns=['delivery_charges'])\n",
    "\n",
    "#subtotal_inr_delete\n",
    "# Delete the subtotal_inr column\n",
    "df = df.drop(columns=['subtotal_inr'])\n",
    "\n",
    "# Remove symbols and commas from original_price_inr\n",
    "df['original_price_inr'] = df['original_price_inr'].astype(str)  # Ensure string\n",
    "df['original_price_inr'] = df['original_price_inr'].str.replace(r'[â‚¹,RsINR\\s]', '', regex=True)\n",
    "\n",
    "# Convert to float\n",
    "df['original_price_inr'] = df['original_price_inr'].astype(float)\n",
    "\n",
    "# Optional: verify\n",
    "print(df['original_price_inr'].head())\n",
    "print(df['original_price_inr'].dtype)  # should show float64\n",
    "\n",
    "# Verify\n",
    "print(df.head())\n",
    "\n",
    "#Customer-city-cleaning\n",
    "#Mumbai_city\n",
    "# Define all variants to replace\n",
    "mumbai_variants = ['Mumbai', 'MUMBAI', 'Mumbai ', 'Bombay', 'mumba']\n",
    "# Replace all variants with 'Mumbai'\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(mumbai_variants, \"Mumbai\")\n",
    "\n",
    "kolkata_variants = ['Kolkata', 'Kolkata ', 'kolkata', 'Calcutta', 'KOLKATA']\n",
    "# Replace all variants with 'Kolkata'\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(kolkata_variants, \"Kolkata\")\n",
    "\n",
    "delhi_variants = ['Delhi', 'New Delhi', 'DELHI', 'Delhi NCR', 'delhi']\n",
    "# Replace all variants with 'Delhi'\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(delhi_variants, \"Delhi\")\n",
    "\n",
    "chennai_variants = ['Chennai', 'Madras', 'CHENNAI', 'chenai', 'Chennai ']\n",
    "# Replace all variants with 'chennai'\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(chennai_variants, \"Chennai\")\n",
    "\n",
    "Bangalore_variants = ['Bangalore', 'BANGALORE',  'Bengalore', 'Bengaluru', 'Banglore']\n",
    "# Replace all variants with 'Bangalore'\n",
    "df[\"customer_city\"] = df[\"customer_city\"].replace(Bangalore_variants, \"Bangalore\")\n",
    "\n",
    "# Find unique values in customer_city\n",
    "unique_customer_city = df['customer_city'].unique()\n",
    "print(\"curtomer_city:\")\n",
    "print(unique_customer_city)\n",
    "value_count_city = df['customer_city'].value_counts()\n",
    "print(value_count_city)\n",
    "\n",
    "# Unique values in each column\n",
    "unique_states = df[\"customer_state\"].unique()\n",
    "unique_tier = df[\"customer_tier\"].unique()\n",
    "unique_spending_tier = df[\"customer_spending_tier\"].unique()\n",
    "unique_payment_method = df[\"payment_method\"].unique()\n",
    "unique_delivery_type = df[\"delivery_type\"].unique()\n",
    "\n",
    "print(\"Unique customer_state:\", unique_states)\n",
    "print(\"Unique customer_tier:\", unique_tier)\n",
    "print(\"Unique customer_spending_tier:\", unique_spending_tier)\n",
    "print(\"unique payment_method:\", unique_payment_method)\n",
    "print(\"unique delivery_type:\", unique_delivery_type)\n",
    "\n",
    "value_payment_method = df['payment_method'].value_counts()\n",
    "print(value_payment_method)\n",
    "\n",
    "# Remove unwanted payment methods\n",
    "df = df[~df['payment_method'].isin(['Wallet', 'BNPL'])]\n",
    "\n",
    "# Optional: confirm removal\n",
    "print(\"âœ… Updated payment method counts:\")\n",
    "print(df['payment_method'].value_counts())\n",
    "\n",
    "\n",
    "print(\"Delivery type counts:\\n\", df[\"delivery_type\"].value_counts())\n",
    "#print(\"\\nCustomer Tire counts:\\n\", df[\"customer_tire\"].value_counts())\n",
    "#print(\"\\nCustomer Spending Tier counts:\\n\", df[\"customer_spending_tier\"].value_counts())\n",
    "\n",
    "#is_festival_sale column droppped\n",
    "# Or inplace\n",
    "df.drop(columns=[\"is_festival_sale\"], inplace=True)\n",
    "\n",
    "#original_price_inr_cleaning\n",
    "# Remove '-' symbol from original_price_inr\n",
    "df[\"original_price_inr\"] = df[\"original_price_inr\"].astype(str).str.replace(\"-\", \"\", regex=False)\n",
    "\n",
    "# Convert back to float (if needed)\n",
    "df[\"original_price_inr\"] = df[\"original_price_inr\"].astype(float)\n",
    "\n",
    "# Find rows where '-' is present in original_price_inr\n",
    "#rows_with_dash = df[df[\"original_price_inr\"].astype(str).str.contains(\"-\")]\n",
    "\n",
    "#print(\"Rows with '-' in original_price_inr:\")\n",
    "#print(rows_with_dash)\n",
    "\n",
    "#price_convert_into_whole_number\n",
    "# Convert float columns to whole numbers (integer)\n",
    "df[\"original_price_inr\"] = df[\"original_price_inr\"].astype(float).round().astype(int)\n",
    "df[\"discount_percent\"] = df[\"discount_percent\"].astype(float).round().astype(int)\n",
    "df[\"discounted_price_inr\"] = df[\"discounted_price_inr\"].astype(float).round().astype(int)\n",
    "df[\"final_amount_inr\"] = df[\"final_amount_inr\"].astype(float).round().astype(int)\n",
    "\n",
    "#discounted_price_checking\n",
    "\n",
    "# Step 1: Calculate expected discounted price\n",
    "df[\"calculated_discounted_price\"] = (df[\"original_price_inr\"] * (1 - df[\"discount_percent\"] / 100)).round()\n",
    "\n",
    "# Step 2: Compare with actual discounted price\n",
    "df[\"discount_check\"] = df[\"calculated_discounted_price\"] == df[\"discounted_price_inr\"]\n",
    "\n",
    "# Step 3: Calculate variation percentage\n",
    "df[\"variation_percent\"] = (\n",
    "    abs(df[\"calculated_discounted_price\"] - df[\"discounted_price_inr\"]) \n",
    "    / df[\"calculated_discounted_price\"] * 100\n",
    ").round(2)\n",
    "\n",
    "# Step 4: Mark as High if > 5%\n",
    "df[\"variation_flag\"] = df[\"variation_percent\"].apply(lambda x: \"High\" if x > 5 else \"OK\")\n",
    "\n",
    "# Step 5: Count how many High\n",
    "high_count = (df[\"variation_flag\"] == \"High\").sum()\n",
    "\n",
    "print(\"Number of High variation rows:\", high_count)\n",
    "print(df[[\"original_price_inr\", \"discount_percent\", \"discounted_price_inr\", \n",
    "          \"calculated_discounted_price\", \"variation_percent\", \"variation_flag\"]])\n",
    "\n",
    "# Delete rows where variation_flag is High\n",
    "df = df[df[\"variation_flag\"] != \"High\"]\n",
    "\n",
    "# Reset index after deletion (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Rows after removing High variation:\", len(df))\n",
    "\n",
    "print(\"Number of rows present:\", df.shape[0])\n",
    "\n",
    "#drop\n",
    "df.drop(columns=[\"calculated_discounted_price\"], inplace=True)\n",
    "df.drop(columns=[\"variation_percent\"], inplace=True)\n",
    "df.drop(columns=[\"variation_flag\"], inplace=True)\n",
    "df.drop(columns=[\"discount_check\"], inplace=True)\n",
    "\n",
    "#discounted_price_inr vs original_price_inr checking\n",
    "# Step 1: Check if discounted_price_inr * quantity = final_amount_inr\n",
    "df[\"amount_check\"] = df.apply(\n",
    "    lambda x: \"correct\" if round(x[\"discounted_price_inr\"] * x[\"quantity\"]) == round(x[\"final_amount_inr\"]) else \"wrong\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 2: Count how many \"wrong\"\n",
    "wrong_count = (df[\"amount_check\"] == \"wrong\").sum()\n",
    "\n",
    "print(\"Number of wrong rows:\", wrong_count)\n",
    "print(df[[\"discounted_price_inr\", \"quantity\", \"final_amount_inr\", \"amount_check\"]])\n",
    "\n",
    "# Delete rows where amount_check is \"wrong\"\n",
    "df = df[df[\"amount_check\"] != \"wrong\"]\n",
    "\n",
    "# Reset index after deletion (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Rows after removing wrong amounts:\", len(df))\n",
    "\n",
    "df.drop(columns=[\"amount_check\"], inplace=True)\n",
    "\n",
    "##Customer_age_group label and delete the null\n",
    "\n",
    "# Define the mapping\n",
    "age_group_map = {\n",
    "    \"17\": 0,\n",
    "    \"18-25\": 1,\n",
    "    \"26-35\": 2,\n",
    "    \"36-45\": 3,\n",
    "    \"46-55\": 4,\n",
    "    \"55+\": 5,\n",
    "    \"+55\": 5\n",
    "}\n",
    "\n",
    "# Ensure customer_age_group is string\n",
    "df[\"customer_age_group\"] = df[\"customer_age_group\"].astype(str)\n",
    "\n",
    "# Create new column with numeric labels\n",
    "df[\"age_group_label\"] = df[\"customer_age_group\"].map(age_group_map)\n",
    "\n",
    "print(df[[\"customer_age_group\", \"age_group_label\"]].head())\n",
    "\n",
    "## Count how many rows have age_group_label 0 (i.e., \"17\")\n",
    "count_17 = (df[\"age_group_label\"] == 0).sum()\n",
    "print(\"Number of rows with 17 in age_group_label:\", count_17)\n",
    "\n",
    "# Delete rows where age_group_label is 0\n",
    "df = df[df[\"age_group_label\"] != 0]\n",
    "\n",
    "# Reset index after deletion (optional)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Rows after removing age_group_label 0:\", len(df))\n",
    "\n",
    "print(\"Number of rows present:\", df.shape[0])\n",
    "\n",
    "#drop Customer_age_group\n",
    "df.drop(columns=[\"customer_age_group\"], inplace=True)\n",
    "\n",
    "#Prime_member_table update\n",
    "#print(df.dtypes)\n",
    "unique_prime_member = df[\"is_prime_member\"].unique()\n",
    "print(\"Unique prime_member:\", unique_prime_member)\n",
    "print(df[\"is_prime_member\"].value_counts())\n",
    "\n",
    "# Convert to string, strip whitespace\n",
    "df['is_prime_member'] = df['is_prime_member'].astype(str).str.strip()\n",
    "\n",
    "# Remove rows where value is '0' or '1'\n",
    "df = df[~df['is_prime_member'].isin(['0', '1'])]\n",
    "\n",
    "Yes_variants = ['True', 'TRUE', 'Yes']\n",
    "# Replace all variants with 'is_primme_member'\n",
    "df[\"is_prime_member\"] = df[\"is_prime_member\"].replace(Yes_variants, \"Yes\")\n",
    "\n",
    "No_variants = ['False', 'FALSE', 'No']\n",
    "# Replace all variants with 'is_prime_member'\n",
    "df[\"is_prime_member\"] = df[\"is_prime_member\"].replace(No_variants, \"No\")\n",
    "\n",
    "print(\"Rows after removing age_group_label 0:\", len(df))\n",
    "\n",
    "#Customer_rating \n",
    "#print(df.dtypes)\n",
    "unique_customer_rating = df[\"customer_rating\"].unique()\n",
    "print(\"customer_rating:\", unique_customer_rating)\n",
    "print(df[\"customer_rating\"].value_counts())\n",
    "df['customer_rating'] = df['customer_rating'].astype(float).round(1)\n",
    "\n",
    "#Is_prime_eligible \n",
    "#print(df.dtypes)\n",
    "unique_is_prime_eligible = df[\"is_prime_eligible\"].unique()\n",
    "print(\"is_prime_eligible:\", unique_is_prime_eligible)\n",
    "print(df[\"is_prime_eligible\"].value_counts())\n",
    "\n",
    "# Convert to string, strip whitespace\n",
    "df['is_prime_eligible'] = df['is_prime_eligible'].astype(str).str.strip()\n",
    "\n",
    "# Remove rows where value is '0' or '1'\n",
    "df = df[~df['is_prime_eligible'].isin(['0', '1'])]\n",
    "\n",
    "#Yes_variants = ['True', 'TRUE', 'Yes']\n",
    "# Replace all variants with 'is_prime_eligible'\n",
    "df[\"is_prime_eligible\"] = df[\"is_prime_eligible\"].replace(Yes_variants, \"Yes\")\n",
    "\n",
    "#No_variants = ['False', 'FALSE', 'No']\n",
    "# Replace all variants with 'is_prime_eligible'\n",
    "df[\"is_prime_eligible\"] = df[\"is_prime_eligible\"].replace(No_variants, \"No\")\n",
    "\n",
    "print(\"Rows after removing age_group_label 0:\", len(df))\n",
    "\n",
    "#delivery_days\n",
    "unique_delivery_days = df[\"delivery_days\"].unique()\n",
    "print(\"delivery_days:\", unique_delivery_days)\n",
    "print(df[\"delivery_days\"].value_counts())\n",
    "# Convert to string and strip whitespace (in case values have spaces)\n",
    "df['delivery_days'] = df['delivery_days'].astype(str).str.strip()\n",
    "\n",
    "# Drop rows with unwanted values\n",
    "df = df[~df['delivery_days'].isin(['-1', '1-2 days', 'Same Day', 'Express', '0'])]\n",
    "print(\"Rows after removing age_group_label 0:\", len(df))\n",
    "\n",
    "##############-- order-date-cleaning-----\n",
    "# Ensure column is string\n",
    "df['order_date'] = df['order_date'].astype(str)\n",
    "\n",
    "# Find rows containing \"/\"\n",
    "mask = df['order_date'].str.contains(\"/\", na=False)\n",
    "\n",
    "# Filtered rows\n",
    "df_with_slash = df[mask]\n",
    "\n",
    "# Count how many\n",
    "count_with_slash = mask.sum()\n",
    "\n",
    "#print(\"Number of rows with '/' in order_date:\", count_with_slash)\n",
    "#print(df_with_slash)\n",
    "# Ensure column is string\n",
    "df['order_date'] = df['order_date'].astype(str)\n",
    "\n",
    "# Keep only rows that do NOT contain \"/\"\n",
    "df = df[~df['order_date'].str.contains(\"/\", na=False)]\n",
    "\n",
    "print(\"Rows after removing order_date_clean:\", len(df))\n",
    "def normalize_date(date_str):\n",
    "    try:\n",
    "        # If it starts with 4 digits, assume yyyy-mm-dd â†’ leave as is\n",
    "        if date_str[:4].isdigit() and date_str[4] in ['-', '/']:\n",
    "            return date_str\n",
    "        else:\n",
    "            # Otherwise parse as dd-mm-yyyy\n",
    "            dt = pd.to_datetime(date_str, dayfirst=True, errors='coerce')\n",
    "            if pd.isna(dt):\n",
    "                return date_str  # leave unrecognized\n",
    "            return dt.strftime(\"%Y-%m-%d\")\n",
    "    except:\n",
    "        return date_str\n",
    "\n",
    "# Apply normalization\n",
    "df['order_date'] = df['order_date'].apply(normalize_date)\n",
    "#print(df.dtypes)\n",
    "#print(df['order_date'].unique())\n",
    "\n",
    "#####################################finding_duplicate-value---###############\n",
    "\n",
    "# Ensure the relevant columns are clean\n",
    "df['customer_id'] = df['customer_id'].astype(str).str.strip()\n",
    "df['order_date'] = df['order_date'].astype(str).str.strip()\n",
    "df['product_id'] = df['product_id'].astype(str).str.strip()\n",
    "df['original_price_inr'] = pd.to_numeric(df['original_price_inr'], errors='coerce')\n",
    "\n",
    "# Flag duplicates\n",
    "df['duplicate_flag'] = df.duplicated(subset=['customer_id', 'order_date', 'product_id', 'original_price_inr'], keep=False)\n",
    "\n",
    "# Convert boolean to 'duplicate' / 'unique'\n",
    "df['duplicate_flag'] = df['duplicate_flag'].map({True: 'duplicate', False: 'unique'})\n",
    "\n",
    "# See the result\n",
    "print(df[['customer_id', 'order_date', 'product_id', 'original_price_inr', 'duplicate_flag']])\n",
    "\n",
    "# Count duplicates\n",
    "duplicate_count = (df['duplicate_flag'] == 'duplicate').sum()\n",
    "\n",
    "# Remove duplicates and keep the first occurrence\n",
    "df = df.drop_duplicates(subset=['customer_id', 'order_date', 'product_id', 'original_price_inr'], keep='first')\n",
    "\n",
    "# Reset index (optional)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#drop Duplicate_flag\n",
    "df.drop(columns=[\"duplicate_flag\"], inplace=True)\n",
    "\n",
    "print(\"Rows after duplicate_clean:\", len(df))\n",
    "\n",
    "\n",
    "# Show count of nulls in each column\n",
    "print(\"Null count per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Show total nulls in entire file\n",
    "print(\"\\nTotal null values:\", df.isnull().sum().sum())\n",
    "\n",
    "# Show rows that contain at least one null\n",
    "print(\"\\nRows with null values:\")\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "#outlinear original_price_inr\n",
    "\n",
    "# Convert column to numeric (in case it has text, â‚¹, etc.)\n",
    "df['original_price_inr'] = pd.to_numeric(df['original_price_inr'], errors='coerce')\n",
    "\n",
    "# Drop null values in the price column\n",
    "df = df.dropna(subset=['original_price_inr'])\n",
    "\n",
    "# Calculate IQR (Interquartile Range)\n",
    "Q1 = df['original_price_inr'].quantile(0.25)\n",
    "Q3 = df['original_price_inr'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count outliers before deletion\n",
    "outlier_count = df[(df['original_price_inr'] < lower_bound) | (df['original_price_inr'] > upper_bound)].shape[0]\n",
    "print(f\"Number of outliers to delete: {outlier_count}\")\n",
    "\n",
    "# Delete outliers\n",
    "df_cleaned = df[(df['original_price_inr'] >= lower_bound) & (df['original_price_inr'] <= upper_bound)]\n",
    "\n",
    "# Show summary after deletion\n",
    "print(f\"Rows before deletion: {len(df)}\")\n",
    "print(f\"Rows after deletion: {len(df_cleaned)}\")\n",
    "print(f\"Deleted rows: {len(df) - len(df_cleaned)}\")\n",
    "\n",
    "#Category\n",
    "# Find unique values in category\n",
    "unique_category = df['category'].unique()\n",
    "print(unique_category)\n",
    "\n",
    "# Assuming your dataframe is df and column is 'category'\n",
    "counts = df['category'].value_counts()\n",
    "print(counts)\n",
    "\n",
    "# Define all variants\n",
    "variants = ['Electronic', 'Electronicss', 'ELECTRONICS', 'Electronics & Accessories']\n",
    "\n",
    "# Replace them all with 'Electronics'\n",
    "df['category'] = df['category'].replace(variants, 'Electronics')\n",
    "\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "\n",
    "output_file = r\"C:\\Users\\Alagu\\DATASCIENCE\\Cleaned_data\\amazon_india_complete_2015_2025_cleaned_03.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"âœ… Cleaned file saved at: {output_file}\")\n",
    "print(\"âœ… Cleaned file saved as 'cleaned_file.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b43dbd-01ef-4678-b8b6-fb6059de8639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad168f-8181-4f5e-83ef-50f636cb7bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
